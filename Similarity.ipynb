{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Similarity Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from itertools import islice\n",
    "from sklearn import preprocessing  # Two samples, with 3 dimensions.\n",
    "\n",
    "\n",
    "\n",
    "path = './data/' # Ensure path exists with relevant data \n",
    "\n",
    "embedding_names = ['bow2','bow5']\n",
    "\n",
    "embedding_names = ['bow2','deps'] # Due to memory issues the datasets are \n",
    "                                    # loaded 2 at a time\n",
    "\n",
    "#\n",
    "# embeddings: list of dicts holding the data for each embedding\n",
    "# dict: {name - embedding name,\n",
    "#       filename - embedding data filename\n",
    "#       words - dict holding the words  and their vectors\n",
    "#    \n",
    "embeddings = []\n",
    "\n",
    "\n",
    "for name in embedding_names:\n",
    "    # words: dict, holds all words and their vectors for each embedding\n",
    "    words = {}\n",
    "    words_normalized = {}\n",
    "    filename = name + '.words.bz2'\n",
    "    embedding_df = pd.read_table(path + filename , sep=' ', header=None)\n",
    "    for index, row in embedding_df.iterrows():\n",
    "        words[row[0]] = row[1:]\n",
    "    \n",
    "    \n",
    "    embedding_vectors = np.stack(list(words.values()))\n",
    "    embedding_vocabulary = np.stack(list(words.keys()))\n",
    "    embeddings.append({'name':name, 'filename': filename, \n",
    "                            'words': words, ' embedding_vectors':  embedding_vectors,\n",
    "                       'embedding_vocabulary': embedding_vocabulary})\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute correlation of similarity score against human judgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation against Simlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Compute the cosine similarity for each word pair in the simlex\n",
    "#\n",
    "\n",
    "\n",
    "import analyze\n",
    "    \n",
    "\n",
    "cosine_similarities = []\n",
    "\n",
    "\n",
    "path = './data/'\n",
    "simlexf = 'SimLex-999/SimLex-999.txt'\n",
    "simlex = pd.read_table(path + simlexf)\n",
    "simlex_sim =  np.array(simlex[\"SimLex999\"]).astype(np.float)\n",
    "\n",
    "MEN_f = 'MEN/MEN_dataset_natural_form_full'\n",
    "MEN = pd.read_table(path + MEN_f, header=None, sep=' ')\n",
    "MEN_sim =  np.array(MEN.ix[:,2]).astype(np.float)\n",
    "\n",
    "similarity_evaluation = pd.DataFrame({})\n",
    "\n",
    "\n",
    "\n",
    "word_pairs = simlex\n",
    "\n",
    "spearman = []\n",
    "pearson = []\n",
    "\n",
    "datasets = {'simlex': simlex_sim, 'MEN': MEN_sim}\n",
    "\n",
    "\n",
    "def compute_correlations(similarities, predicted):\n",
    "        \n",
    "    df = pd.DataFrame({'control': similarities, 'predicted': predicted})\n",
    "    return( {'pearson': df.corr(method = 'pearson')['control'][1], \n",
    "            'spearman': df.corr(method = 'spearman')['control'][1]})\n",
    "    \n",
    "\n",
    "# Calculate cosine similarity between each pair of words in the simlex\n",
    "\n",
    "words_pairs = simlex \n",
    "dataset = 'simlex'\n",
    "for embedding in embeddings:\n",
    "    word_vectors = embedding['words']\n",
    "    cosine_similarities = []\n",
    "    cosine_similarities = analyze.evaluate_similarity(word_pairs, word_vectors)\n",
    "    embedding.update({'cosine_similarities':cosine_similarities})\n",
    "\n",
    "    cors = compute_correlations(simlex_sim, cosine_similarities)\n",
    "    pearson.append(cors['pearson'])\n",
    "    spearman.append(cors['spearman'])\n",
    "    \n",
    "similarity_evaluation = pd.DataFrame({'embedding': embedding_names, \n",
    "                                      'spearman': spearman,\n",
    "                                     'pearson': pearson})\n",
    "\n",
    "\n",
    "print(similarity_evaluation)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation against MEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spearman = []\n",
    "pearson = []   \n",
    "\n",
    "word_pairs = MEN\n",
    "\n",
    "for embedding in embeddings:\n",
    "    word_vectors = embedding['words']\n",
    "    cosine_similarities = []\n",
    "    cosine_similarities = analyze.evaluate_similarity(word_pairs, word_vectors)\n",
    "    embedding.update({'cosine_similarities':cosine_similarities})\n",
    "\n",
    "    cors = compute_correlations(MEN_sim, cosine_similarities)\n",
    "    pearson.append(cors['pearson'])\n",
    "    spearman.append(cors['spearman'])\n",
    "    \n",
    "        \n",
    "similarity_evaluation = pd.DataFrame({'embedding': embedding_names, \n",
    "                                      'spearman': spearman,\n",
    "                                     'pearson': pearson})\n",
    "\n",
    "\n",
    "    \n",
    "print(similarity_evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the scores for example word-pairs for each embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Qualitative Comparison\n",
    "# Choose a few random  word pair indices to compare the score for the three embeddings\n",
    "# Choose MEN or simlex dataset\n",
    "\n",
    "dataset = simlex[['word1','word2', 'SimLex999']]   # MEN or simlex\n",
    "dataset = MEN   # MEN or simlex\n",
    "\n",
    "indices = [0,1,940]\n",
    "for ind in indices:\n",
    "    print('\\n',dataset.ix[ind,0], dataset.ix[ind,1] )\n",
    "    cos_sims = dataset.ix[:,2]\n",
    "    normalized =(cos_sims - min(cos_sims))/(max(cos_sims)-min(cos_sims))\n",
    "    print('human', normalized[ind])\n",
    "    \n",
    "    for embedding in embeddings:\n",
    "        cos_sims = embedding['cosine_similarities']\n",
    "        normalized =(cos_sims - min(cos_sims))/(max(cos_sims)-min(cos_sims))\n",
    "        print(\"%s %.2f\"%(embedding['name'],normalized[ind]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def closest_words(embedding_vectors,embedding_vocabulary, word, k, exclude=[]):\n",
    "    #\n",
    "    # Obtain the k most similar words based on cosine similarity\n",
    "    #\n",
    "    D = pairwise_distances(embedding_vectors, word.reshape(1, -1), metric='cosine')\n",
    "    possible_answers=[]\n",
    "    kwords=k\n",
    "    if exclude:\n",
    "        kwords=k+len(exclude)\n",
    "    for id in D.argsort(axis=0).flatten()[0:kwords]:\n",
    "        \n",
    "        # Exclude words in query\n",
    "        if embedding_vocabulary[id] not in (exclude):\n",
    "            possible_answers.append(embedding_vocabulary[id])\n",
    "    return(possible_answers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the 5 most similar words for a query word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Qualitative checks\n",
    "#\n",
    "#\n",
    "# Look into 5 most similar words\n",
    "# Choose a word\n",
    "word_to_check='old'\n",
    "word_to_check='smart'\n",
    "\n",
    "for embedding in embeddings:\n",
    "    words = embedding['words']\n",
    "    most_similar = closest_words(embedding['embedding_vectors'],\n",
    "                                 embedding['embedding_vocabulary'], \n",
    "                                 words[word_to_check], 6, exclude=[])\n",
    "    \n",
    "    print(most_similar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
