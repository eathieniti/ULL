{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "# add gensim source code fro this path\n",
    "sys.path.insert(0, \"../../../\")\n",
    "sys.path.insert(0, \"../../gensim/\")\n",
    "\n",
    "# import modules & set up logging\n",
    "import gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the training data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from smart_open import smart_open\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in smart_open(os.path.join(self.dirname, fname), 'r'):\n",
    "                yield line.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clean stopwords\n",
    "2. choose most frequent words replace 'the' etc with unknowns, also stopwords\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch  basic skipgram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to learn the embeddings we need a corpus and a method to read it and create the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1060d9f50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create context and targer pairs from the corpus\n",
    "\n",
    "context: length k (k words surrounding the target) - it is the index of each context word in the vocabulary\n",
    "eg. tensor([ 37,  30,   7,   6])\n",
    "\n",
    "\n",
    "target: length 1 - index of target word\n",
    "eg. tensor([40])\n",
    "\n",
    "pytorch notes:\n",
    "Note that the input to NLLLoss is a vector of log probabilities, and a target label. It doesnâ€™t compute the log probabilities for us. This is why the last layer of our network is log softmax. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"full\"\n",
    "if mode=='full':\n",
    "    my_sentences_fn = '../..//ULL/data/Practical2/wa/english_full/'\n",
    "else:\n",
    "    my_sentences_fn = '../..//ULL/data/Practical2/wa/english/'\n",
    "\n",
    "sentences = MySentences(my_sentences_fn) # a memory-friendly iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the training data\n",
    "\n",
    "vocabulary = []\n",
    "for sentence in sentences:\n",
    "    for token in sentence:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "window_size = 2\n",
    "context_size = window_size\n",
    "idx_pairs = []\n",
    "data=[]\n",
    "bayesian_data=[]\n",
    "# for each sentence\n",
    "for sentence in sentences:\n",
    "    indices = [word2idx[word] for word in sentence]\n",
    "    # for each word, threated as center word\n",
    "    for center_word_pos in range(len(indices)):\n",
    "        # for each window position\n",
    "        contexts_for_word = []\n",
    "\n",
    "        for w in range(-window_size, window_size + 1):\n",
    "            context_word_pos = center_word_pos + w\n",
    "            # make soure not jump out sentence\n",
    "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
    "                continue\n",
    "            context_word_idx = indices[context_word_pos]\n",
    "            data.append((context_word_idx, indices[center_word_pos]))\n",
    "            \n",
    "            # this is used for bayesian to keep all contexts  of a word together\n",
    "            contexts_for_word.append(context_word_idx)\n",
    "        bayesian_data.append((contexts_for_word, indices[center_word_pos]))\n",
    "\n",
    "\n",
    "\n",
    "vocab = vocabulary\n",
    "vocab_size = vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for sentence in sentences:\n",
    "    for i in range(len(sentence)):\n",
    "        for j in range(i-window, i+window+1):\n",
    "            if i != j and j>=0 and j<len(sentence):\n",
    "                if (not (sentence[i] in stopWords or sentence[i] in string.punctuation or sentence[i].isdigit() or\n",
    "                    sentence[j] in stopWords or  sentence[j] in string.punctuation or sentence[j].isdigit())):\n",
    "                    # data.append(sentence[i])\n",
    "                    # labels.append(sentence[j])\n",
    "                    if sentence[i] in vocab:\n",
    "                        data.append(w2i[sentence[i]])\n",
    "                    else:\n",
    "                        data.append(w2i[unk])\n",
    "                    if sentence[j] in vocab:\n",
    "                        labels.append(w2i[sentence[j]])\n",
    "                    else:\n",
    "                        labels.append(w2i[unk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "class skipgram(nn.Module):  \n",
    "    def __init__(self, vocab_size, embedding_dim):  \n",
    "        super(skipgram,self).__init__()   \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) # embeddings\n",
    "        self.linear1 = nn.Linear(embedding_dim, vocab_size) # \n",
    "\n",
    "  \n",
    "    def forward(self, cword_var): \n",
    "        embeds = self.embeddings(cword_var)  \n",
    "        out = self.linear1(embeds)  \n",
    "        log_probs = F.log_softmax(out)  \n",
    "        return log_probs  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "def make_context_vector(context, word_to_ix):  \n",
    "    idxs = [word_to_ix[w] for w in context]  \n",
    "    tensor = torch.LongTensor(idxs)  \n",
    "    return Variable(tensor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efiathieniti/miniconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 tensor(8.2481)\n",
      "epoch 1 tensor(8.1486)\n",
      "epoch 2 tensor(8.0160)\n",
      "epoch 3 tensor(7.8684)\n",
      "epoch 4 tensor(7.7211)\n",
      "epoch 5 tensor(7.5762)\n",
      "epoch 6 tensor(7.4337)\n",
      "epoch 7 tensor(7.2947)\n",
      "epoch 8 tensor(7.1604)\n",
      "epoch 9 tensor(7.0318)\n",
      "epoch 10 tensor(6.9099)\n",
      "epoch 11 tensor(6.7955)\n",
      "epoch 12 tensor(6.6890)\n",
      "epoch 13 tensor(6.5908)\n",
      "epoch 14 tensor(6.5010)\n",
      "epoch 15 tensor(6.4195)\n",
      "epoch 16 tensor(6.3461)\n",
      "epoch 17 tensor(6.2805)\n",
      "epoch 18 tensor(6.2222)\n",
      "epoch 19 tensor(6.1708)\n",
      "epoch 20 tensor(6.1255)\n",
      "epoch 21 tensor(6.0860)\n",
      "epoch 22 tensor(6.0515)\n",
      "epoch 23 tensor(6.0216)\n",
      "epoch 24 tensor(5.9958)\n",
      "epoch 25 tensor(5.9736)\n",
      "epoch 26 tensor(5.9546)\n",
      "epoch 27 tensor(5.9384)\n",
      "epoch 28 tensor(5.9248)\n",
      "epoch 29 tensor(5.9133)\n",
      "epoch 30 tensor(5.9037)\n",
      "epoch 31 tensor(5.8958)\n",
      "epoch 32 tensor(5.8894)\n",
      "epoch 33 tensor(5.8842)\n",
      "epoch 34 tensor(5.8802)\n",
      "epoch 35 tensor(5.8772)\n",
      "epoch 36 tensor(5.8751)\n",
      "epoch 37 tensor(5.8736)\n",
      "epoch 38 tensor(5.8728)\n",
      "epoch 39 tensor(5.8726)\n",
      "epoch 40 tensor(5.8728)\n",
      "epoch 41 tensor(5.8734)\n",
      "epoch 42 tensor(5.8744)\n",
      "epoch 43 tensor(5.8757)\n",
      "epoch 44 tensor(5.8772)\n",
      "epoch 45 tensor(5.8790)\n",
      "epoch 46 tensor(5.8809)\n",
      "epoch 47 tensor(5.8830)\n",
      "epoch 48 tensor(5.8852)\n",
      "epoch 49 tensor(5.8874)\n",
      "epoch 50 tensor(5.8898)\n",
      "epoch 51 tensor(5.8921)\n",
      "epoch 52 tensor(5.8945)\n",
      "epoch 53 tensor(5.8969)\n",
      "epoch 54 tensor(5.8992)\n",
      "epoch 55 tensor(5.9015)\n",
      "epoch 56 tensor(5.9038)\n",
      "epoch 57 tensor(5.9061)\n",
      "epoch 58 tensor(5.9083)\n",
      "epoch 59 tensor(5.9105)\n",
      "epoch 60 tensor(5.9126)\n",
      "epoch 61 tensor(5.9147)\n",
      "epoch 62 tensor(5.9167)\n",
      "epoch 63 tensor(5.9186)\n",
      "epoch 64 tensor(5.9205)\n",
      "epoch 65 tensor(5.9222)\n",
      "epoch 66 tensor(5.9239)\n",
      "epoch 67 tensor(5.9255)\n",
      "epoch 68 tensor(5.9270)\n",
      "epoch 69 tensor(5.9284)\n",
      "epoch 70 tensor(5.9298)\n",
      "epoch 71 tensor(5.9312)\n",
      "epoch 72 tensor(5.9324)\n",
      "epoch 73 tensor(5.9336)\n",
      "epoch 74 tensor(5.9347)\n",
      "epoch 75 tensor(5.9357)\n",
      "epoch 76 tensor(5.9367)\n",
      "epoch 77 tensor(5.9376)\n",
      "epoch 78 tensor(5.9385)\n",
      "epoch 79 tensor(5.9394)\n",
      "epoch 80 tensor(5.9402)\n",
      "epoch 81 tensor(5.9409)\n",
      "epoch 82 tensor(5.9417)\n",
      "epoch 83 tensor(5.9424)\n",
      "epoch 84 tensor(5.9430)\n",
      "epoch 85 tensor(5.9436)\n",
      "epoch 86 tensor(5.9442)\n",
      "epoch 87 tensor(5.9447)\n",
      "epoch 88 tensor(5.9452)\n",
      "epoch 89 tensor(5.9457)\n",
      "epoch 90 tensor(5.9461)\n",
      "epoch 91 tensor(5.9465)\n",
      "epoch 92 tensor(5.9469)\n",
      "epoch 93 tensor(5.9472)\n",
      "epoch 94 tensor(5.9475)\n",
      "epoch 95 tensor(5.9478)\n",
      "epoch 96 tensor(5.9481)\n",
      "epoch 97 tensor(5.9483)\n",
      "epoch 98 tensor(5.9486)\n",
      "epoch 99 tensor(5.9488)\n",
      "[tensor(1.00000e+05 *\n",
      "       [ 1.8765]), tensor(1.00000e+05 *\n",
      "       [ 1.7740]), tensor(1.00000e+05 *\n",
      "       [ 1.7062]), tensor(1.00000e+05 *\n",
      "       [ 1.6579]), tensor(1.00000e+05 *\n",
      "       [ 1.6213]), tensor(1.00000e+05 *\n",
      "       [ 1.5925]), tensor(1.00000e+05 *\n",
      "       [ 1.5691]), tensor(1.00000e+05 *\n",
      "       [ 1.5496]), tensor(1.00000e+05 *\n",
      "       [ 1.5330]), tensor(1.00000e+05 *\n",
      "       [ 1.5186]), tensor(1.00000e+05 *\n",
      "       [ 1.5059]), tensor(1.00000e+05 *\n",
      "       [ 1.4946]), tensor(1.00000e+05 *\n",
      "       [ 1.4845]), tensor(1.00000e+05 *\n",
      "       [ 1.4753]), tensor(1.00000e+05 *\n",
      "       [ 1.4668]), tensor(1.00000e+05 *\n",
      "       [ 1.4589]), tensor(1.00000e+05 *\n",
      "       [ 1.4516]), tensor(1.00000e+05 *\n",
      "       [ 1.4448]), tensor(1.00000e+05 *\n",
      "       [ 1.4383]), tensor(1.00000e+05 *\n",
      "       [ 1.4322]), tensor(1.00000e+05 *\n",
      "       [ 1.4264]), tensor(1.00000e+05 *\n",
      "       [ 1.4209]), tensor(1.00000e+05 *\n",
      "       [ 1.4156]), tensor(1.00000e+05 *\n",
      "       [ 1.4106]), tensor(1.00000e+05 *\n",
      "       [ 1.4057]), tensor(1.00000e+05 *\n",
      "       [ 1.4011]), tensor([ 1.3966e+05]), tensor(1.00000e+05 *\n",
      "       [ 1.3923]), tensor(1.00000e+05 *\n",
      "       [ 1.3881]), tensor(1.00000e+05 *\n",
      "       [ 1.3841]), tensor(1.00000e+05 *\n",
      "       [ 1.3801]), tensor(1.00000e+05 *\n",
      "       [ 1.3763]), tensor(1.00000e+05 *\n",
      "       [ 1.3726]), tensor(1.00000e+05 *\n",
      "       [ 1.3691]), tensor(1.00000e+05 *\n",
      "       [ 1.3656]), tensor(1.00000e+05 *\n",
      "       [ 1.3622]), tensor(1.00000e+05 *\n",
      "       [ 1.3589]), tensor(1.00000e+05 *\n",
      "       [ 1.3556]), tensor(1.00000e+05 *\n",
      "       [ 1.3525]), tensor(1.00000e+05 *\n",
      "       [ 1.3494]), tensor(1.00000e+05 *\n",
      "       [ 1.3464]), tensor(1.00000e+05 *\n",
      "       [ 1.3435]), tensor(1.00000e+05 *\n",
      "       [ 1.3406]), tensor(1.00000e+05 *\n",
      "       [ 1.3378]), tensor(1.00000e+05 *\n",
      "       [ 1.3351]), tensor(1.00000e+05 *\n",
      "       [ 1.3324]), tensor(1.00000e+05 *\n",
      "       [ 1.3298]), tensor(1.00000e+05 *\n",
      "       [ 1.3272]), tensor(1.00000e+05 *\n",
      "       [ 1.3246]), tensor(1.00000e+05 *\n",
      "       [ 1.3222]), tensor(1.00000e+05 *\n",
      "       [ 1.3197]), tensor(1.00000e+05 *\n",
      "       [ 1.3173]), tensor(1.00000e+05 *\n",
      "       [ 1.3150]), tensor(1.00000e+05 *\n",
      "       [ 1.3127]), tensor(1.00000e+05 *\n",
      "       [ 1.3104]), tensor(1.00000e+05 *\n",
      "       [ 1.3082]), tensor(1.00000e+05 *\n",
      "       [ 1.3060]), tensor(1.00000e+05 *\n",
      "       [ 1.3038]), tensor(1.00000e+05 *\n",
      "       [ 1.3017]), tensor(1.00000e+05 *\n",
      "       [ 1.2996]), tensor(1.00000e+05 *\n",
      "       [ 1.2976]), tensor(1.00000e+05 *\n",
      "       [ 1.2956]), tensor(1.00000e+05 *\n",
      "       [ 1.2936]), tensor(1.00000e+05 *\n",
      "       [ 1.2916]), tensor(1.00000e+05 *\n",
      "       [ 1.2897]), tensor(1.00000e+05 *\n",
      "       [ 1.2878]), tensor(1.00000e+05 *\n",
      "       [ 1.2859]), tensor(1.00000e+05 *\n",
      "       [ 1.2841]), tensor(1.00000e+05 *\n",
      "       [ 1.2823]), tensor(1.00000e+05 *\n",
      "       [ 1.2805]), tensor(1.00000e+05 *\n",
      "       [ 1.2787]), tensor(1.00000e+05 *\n",
      "       [ 1.2770]), tensor(1.00000e+05 *\n",
      "       [ 1.2753]), tensor(1.00000e+05 *\n",
      "       [ 1.2736]), tensor(1.00000e+05 *\n",
      "       [ 1.2719]), tensor(1.00000e+05 *\n",
      "       [ 1.2703]), tensor(1.00000e+05 *\n",
      "       [ 1.2686]), tensor(1.00000e+05 *\n",
      "       [ 1.2670]), tensor(1.00000e+05 *\n",
      "       [ 1.2655]), tensor(1.00000e+05 *\n",
      "       [ 1.2639]), tensor(1.00000e+05 *\n",
      "       [ 1.2624]), tensor(1.00000e+05 *\n",
      "       [ 1.2608]), tensor(1.00000e+05 *\n",
      "       [ 1.2593]), tensor(1.00000e+05 *\n",
      "       [ 1.2578]), tensor(1.00000e+05 *\n",
      "       [ 1.2564]), tensor([ 1.2549e+05]), tensor(1.00000e+05 *\n",
      "       [ 1.2535]), tensor(1.00000e+05 *\n",
      "       [ 1.2521]), tensor(1.00000e+05 *\n",
      "       [ 1.2507]), tensor(1.00000e+05 *\n",
      "       [ 1.2493]), tensor(1.00000e+05 *\n",
      "       [ 1.2479]), tensor(1.00000e+05 *\n",
      "       [ 1.2465]), tensor(1.00000e+05 *\n",
      "       [ 1.2452]), tensor(1.00000e+05 *\n",
      "       [ 1.2439]), tensor(1.00000e+05 *\n",
      "       [ 1.2426]), tensor(1.00000e+05 *\n",
      "       [ 1.2413]), tensor(1.00000e+05 *\n",
      "       [ 1.2400]), tensor(1.00000e+05 *\n",
      "       [ 1.2387]), tensor(1.00000e+05 *\n",
      "       [ 1.2375]), tensor(1.00000e+05 *\n",
      "       [ 1.2362])]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE=context_size\n",
    "  \n",
    "embedding_dims = 50\n",
    "\n",
    "  \n",
    "#make_context_vector(data[0][0], word_to_ix)  # example  \n",
    "  \n",
    "# loss model optimizer  \n",
    "losses = []  \n",
    "loss_function = nn.NLLLoss()  \n",
    "model = skipgram(vocab_size, embedding_dim=embedding_dims)  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)  \n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):  \n",
    "    total_loss = torch.FloatTensor([0])  \n",
    "    for context_words, cword in data: \n",
    "\n",
    "        context_var = torch.LongTensor([context_words]) \n",
    "        cword_var = Variable(torch.LongTensor([cword]))  \n",
    "        model.zero_grad()  \n",
    "        # input to model is the central word\n",
    "        log_probs = model(cword_var)  \n",
    "        loss = loss_function(log_probs, context_var)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "        total_loss += loss.data  \n",
    "    print(\"epoch\", epoch, loss.data)\n",
    "    #print(total_loss)\n",
    "    losses.append(total_loss)  \n",
    "print(losses) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = model.embeddings.weight\n",
    "import csv\n",
    "\n",
    "embeddings_file=\"embeddings_final_\" + str(mode) + str(epochs) + \"_\" +str(embedding_dims) + \"_scratch.txt\"\n",
    "with open(embeddings_file, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter = ' ')\n",
    "    writer.writerow([vocabulary_size, embedding_dims])\n",
    "\n",
    "    for i in range(embeddings.size()[0]):\n",
    "        word = idx2word[i]\n",
    "\n",
    "        embedding = embeddings[i, :]\n",
    "        #print(embedding)\n",
    "        embedding = list(embedding.data.numpy()) \n",
    "        line = [word] + embedding\n",
    "        writer.writerow(line)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the embeddings learned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_file=\"embeddings_full100_100_final.txt\"\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "#word_vectors = KeyedVectors.load_word2vec_format('../../../ULL/data/bow2.words.bz2', binary=False)  # C text format\n",
    "word_vectors = KeyedVectors.load_word2vec_format(embeddings_file, binary=False)  # C binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.134572\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.similarity('message', 'issue'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0188806\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.similarity('disturbed', 'pervasive'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embeddings_final_full100_50_scratch.txt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.31042904413301226, 0.13097256206792052),\n",
       " SpearmanrResult(correlation=0.34923076923076918, pvalue=0.087060632485273348),\n",
       " 92.91784702549575)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.evaluate_word_pairs(\"../../gensim/gensim/test/test_data/wordsim353.tsv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "For each word/training point (xi) calculate elbo (loss)\n",
    "xi - training points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the word, contexts for bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([119, 104, 25, 121], 120)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_data[200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "class bayesian_skipgram(nn.Module):  \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(bayesian_skipgram,self).__init__()   \n",
    "        \n",
    "        hidden_dim = 150\n",
    "        # embeddings lookup\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) # embeddings\n",
    "        self.linear1 = nn.Linear(embedding_dim, vocab_size) #\n",
    "        \n",
    "        \n",
    "        # M linear projection [hid_dim, 2 * embd_dim]\n",
    "        self.M_linear = nn.Linear(2*embedding_dim, embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.U = nn.Linear(embedding_dim, embedding_dim) #\n",
    "        self.W = nn.Linear(embedding_dim, embedding_dim) #\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, cword_var, context_var): \n",
    "        \n",
    "        # contexts_emb: Rcj, cword_emb: \n",
    "        contexts_emb = self.embeddings(context_var) \n",
    "        print(\"contexts_emb\",contexts_emb.size())\n",
    "        cword_emb = self.embeddings(cword_var).view(1,-1)\n",
    "        cwords_emb = cword_emb.repeat(1,contexts_emb.size()[1],1)\n",
    "        \n",
    "        # concatenate word and context\n",
    "        # (1, window_size, 2*emb_dim)\n",
    "        word_contexts = torch.cat((cwords_emb, contexts_emb),2)\n",
    "        print(\"word_contexts\",word_contexts.size())\n",
    "        \n",
    "        #\n",
    "        # linear projection, M\n",
    "        # (1, window_size, 2*emb_dim)\n",
    "        #\n",
    "        word_contexts = self.M_linear(word_contexts)\n",
    "        print(\"word_contexts_M\",word_contexts.size())\n",
    "\n",
    "        word_contexts = self.relu(word_contexts)\n",
    "        \n",
    "        # sum to collapse window_size dimension\n",
    "        sum_contexts = torch.sum(word_contexts, 1)\n",
    "        print(\"sum_contexts\",sum_contexts.size())\n",
    "\n",
    "        #\n",
    "        # obtain the mu and sigma \n",
    "        #\n",
    "        \n",
    "        mu = self.U(sum_contexts)\n",
    "        sigma = self.W(sum_contexts)\n",
    "        print(\"mu\",mu.size(),\"sigma\", sigma.size())\n",
    "        \n",
    "        out = self.linear1(sum_contexts)  \n",
    "        log_probs = F.log_softmax(sum_contexts) \n",
    "        \n",
    "        #\n",
    "        # Do the sampling\n",
    "        #\n",
    "        \n",
    "        return log_probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contexts_emb torch.Size([1, 4, 100])\n",
      "word_contexts torch.Size([1, 4, 200])\n",
      "word_contexts_M torch.Size([1, 4, 100])\n",
      "sum_contexts torch.Size([1, 100])\n",
      "mu torch.Size([1, 100]) sigma torch.Size([1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efiathieniti/miniconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:54: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524589329605/work/aten/src/THNN/generic/ClassNLLCriterion.c:22",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-3f7744e2a345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# input to model is the central word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcword_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/efiathieniti/miniconda3/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/efiathieniti/miniconda3/envs/py35/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         return F.nll_loss(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 193\u001b[0;31m                           self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/efiathieniti/miniconda3/envs/py35/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524589329605/work/aten/src/THNN/generic/ClassNLLCriterion.c:22"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE=context_size\n",
    "  \n",
    "embedding_dims = 100\n",
    "\n",
    "  \n",
    "#make_context_vector(data[0][0], word_to_ix)  # example  \n",
    "  \n",
    "# loss model optimizer  \n",
    "losses = []  \n",
    "loss_function = nn.NLLLoss()  \n",
    "model = bayesian_skipgram(vocab_size, embedding_dim=embedding_dims)  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)  \n",
    "\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):  \n",
    "    total_loss = torch.FloatTensor([0])  \n",
    "    for context_words, cword in bayesian_data[100:]: \n",
    "        context_var = torch.LongTensor([context_words]) \n",
    "        cword_var = Variable(torch.LongTensor([cword]))  \n",
    "        model.zero_grad()  \n",
    "        # input to model is the central word\n",
    "        log_probs = model(cword_var, context_var)  \n",
    "        loss = loss_function(log_probs, context_var)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "        total_loss += loss.data  \n",
    "    print(\"epoch\", epoch, loss.data)\n",
    "    #print(total_loss)\n",
    "    losses.append(total_loss)  \n",
    "print(losses) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
